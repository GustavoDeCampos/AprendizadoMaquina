# Função de k-fold cross-validation
def cross_validation(model, X, y, k=5):
    fold_size = len(y) // k
    indices = np.arange(len(y))
    np.random.shuffle(indices)
    
    scores = []
    
    for i in range(k):
        test_indices = indices[i * fold_size: (i + 1) * fold_size]
        train_indices = np.concatenate((indices[:i * fold_size], indices[(i + 1) * fold_size:]))
        
        X_train, X_test = X[train_indices], X[test_indices]
        y_train, y_test = y[train_indices], y[test_indices]

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        # Calcular a matriz de confusão
        conf_matrix = confusion_matrix(y_test, y_pred)

        # Calcular métricas
        acc = accuracy(conf_matrix)
        precisions = precision(conf_matrix)
        recalls = recall(conf_matrix)
        f1_scores = f1_score(conf_matrix)

        scores.append(acc)
        
        # Exibir resultados
        print(f'Fold {i+1} Acurácia: {acc:.4f}')
        print('Matriz de Confusão:')
        print(conf_matrix)  # Imprimir a matriz de confusão
        print('Precisão por classe:', precisions)
        print('Recall por classe:', recalls)
        print('F1 Score por classe:', f1_scores)
    
    avg_score = np.mean(scores)
    print(f'Média da acurácia após {k} folds: {avg_score:.4f}')
    return avg_score
